{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.utils.movie_dataset_etl import MovieDatasetEtl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_movie = MovieDatasetEtl(\"MOVIES\", \"MOVIE_BASE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset URL: https://www.kaggle.com/datasets/rounakbanik/the-movies-dataset\n",
      "Dataset 'rounakbanik/the-movies-dataset' downloaded successfully to './plugins/assets/data/the-movies-dataset'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\iqbal\\Downloads\\Data\\Data Engineer\\Portfolio\\plugins\\utils\\movie_dataset_etl.py:35: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  movies_metadata = pd.read_csv(f\"{file_dictionary}/movies_metadata.csv\")\n"
     ]
    }
   ],
   "source": [
    "extracted = my_movie.extract(\"./lib/assets/data/the-movies-dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = my_movie.transform(extracted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully written to s3://project-etl-iqbal/etl/cast.parquet\n",
      "Data successfully written to s3://project-etl-iqbal/etl/crew.parquet\n",
      "Data successfully written to s3://project-etl-iqbal/etl/keywords.parquet\n",
      "Data successfully written to s3://project-etl-iqbal/etl/links.parquet\n",
      "Data successfully written to s3://project-etl-iqbal/etl/movies_metadata.parquet\n",
      "Data successfully written to s3://project-etl-iqbal/etl/belongs_to_collection.parquet\n",
      "Data successfully written to s3://project-etl-iqbal/etl/genres.parquet\n",
      "Data successfully written to s3://project-etl-iqbal/etl/production_companies.parquet\n",
      "Data successfully written to s3://project-etl-iqbal/etl/production_countries.parquet\n",
      "Data successfully written to s3://project-etl-iqbal/etl/spoken_languages.parquet\n",
      "Data successfully written to s3://project-etl-iqbal/etl/ratings.parquet\n",
      "Table MOVIES.MOVIE_BASE.cast created sucessfully\n",
      "Executing truncate query: TRUNCATE TABLE MOVIES.MOVIE_BASE.cast\n",
      "Executing copy query: \n",
      "            COPY INTO MOVIES.MOVIE_BASE.cast\n",
      "            FROM @S3_STAGE/etl/cast.parquet\n",
      "            FILE_FORMAT = (TYPE = PARQUET)\n",
      "            MATCH_BY_COLUMN_NAME = 'CASE_INSENSITIVE'\n",
      "        \n",
      "Successfully loaded data into cast\n",
      "Table MOVIES.MOVIE_BASE.crew created sucessfully\n",
      "Executing truncate query: TRUNCATE TABLE MOVIES.MOVIE_BASE.crew\n",
      "Executing copy query: \n",
      "            COPY INTO MOVIES.MOVIE_BASE.crew\n",
      "            FROM @S3_STAGE/etl/crew.parquet\n",
      "            FILE_FORMAT = (TYPE = PARQUET)\n",
      "            MATCH_BY_COLUMN_NAME = 'CASE_INSENSITIVE'\n",
      "        \n",
      "Successfully loaded data into crew\n",
      "Table MOVIES.MOVIE_BASE.keywords created sucessfully\n",
      "Executing truncate query: TRUNCATE TABLE MOVIES.MOVIE_BASE.keywords\n",
      "Executing copy query: \n",
      "            COPY INTO MOVIES.MOVIE_BASE.keywords\n",
      "            FROM @S3_STAGE/etl/keywords.parquet\n",
      "            FILE_FORMAT = (TYPE = PARQUET)\n",
      "            MATCH_BY_COLUMN_NAME = 'CASE_INSENSITIVE'\n",
      "        \n",
      "Successfully loaded data into keywords\n",
      "Table MOVIES.MOVIE_BASE.links created sucessfully\n",
      "Executing truncate query: TRUNCATE TABLE MOVIES.MOVIE_BASE.links\n",
      "Executing copy query: \n",
      "            COPY INTO MOVIES.MOVIE_BASE.links\n",
      "            FROM @S3_STAGE/etl/links.parquet\n",
      "            FILE_FORMAT = (TYPE = PARQUET)\n",
      "            MATCH_BY_COLUMN_NAME = 'CASE_INSENSITIVE'\n",
      "        \n",
      "Successfully loaded data into links\n",
      "Table MOVIES.MOVIE_BASE.movies_metadata created sucessfully\n",
      "Executing truncate query: TRUNCATE TABLE MOVIES.MOVIE_BASE.movies_metadata\n",
      "Executing copy query: \n",
      "            COPY INTO MOVIES.MOVIE_BASE.movies_metadata\n",
      "            FROM @S3_STAGE/etl/movies_metadata.parquet\n",
      "            FILE_FORMAT = (TYPE = PARQUET)\n",
      "            MATCH_BY_COLUMN_NAME = 'CASE_INSENSITIVE'\n",
      "        \n",
      "Successfully loaded data into movies_metadata\n",
      "Table MOVIES.MOVIE_BASE.belongs_to_collection created sucessfully\n",
      "Executing truncate query: TRUNCATE TABLE MOVIES.MOVIE_BASE.belongs_to_collection\n",
      "Executing copy query: \n",
      "            COPY INTO MOVIES.MOVIE_BASE.belongs_to_collection\n",
      "            FROM @S3_STAGE/etl/belongs_to_collection.parquet\n",
      "            FILE_FORMAT = (TYPE = PARQUET)\n",
      "            MATCH_BY_COLUMN_NAME = 'CASE_INSENSITIVE'\n",
      "        \n",
      "Successfully loaded data into belongs_to_collection\n",
      "Table MOVIES.MOVIE_BASE.genres created sucessfully\n",
      "Executing truncate query: TRUNCATE TABLE MOVIES.MOVIE_BASE.genres\n",
      "Executing copy query: \n",
      "            COPY INTO MOVIES.MOVIE_BASE.genres\n",
      "            FROM @S3_STAGE/etl/genres.parquet\n",
      "            FILE_FORMAT = (TYPE = PARQUET)\n",
      "            MATCH_BY_COLUMN_NAME = 'CASE_INSENSITIVE'\n",
      "        \n",
      "Successfully loaded data into genres\n",
      "Table MOVIES.MOVIE_BASE.production_companies created sucessfully\n",
      "Executing truncate query: TRUNCATE TABLE MOVIES.MOVIE_BASE.production_companies\n",
      "Executing copy query: \n",
      "            COPY INTO MOVIES.MOVIE_BASE.production_companies\n",
      "            FROM @S3_STAGE/etl/production_companies.parquet\n",
      "            FILE_FORMAT = (TYPE = PARQUET)\n",
      "            MATCH_BY_COLUMN_NAME = 'CASE_INSENSITIVE'\n",
      "        \n",
      "Successfully loaded data into production_companies\n",
      "Table MOVIES.MOVIE_BASE.production_countries created sucessfully\n",
      "Executing truncate query: TRUNCATE TABLE MOVIES.MOVIE_BASE.production_countries\n",
      "Executing copy query: \n",
      "            COPY INTO MOVIES.MOVIE_BASE.production_countries\n",
      "            FROM @S3_STAGE/etl/production_countries.parquet\n",
      "            FILE_FORMAT = (TYPE = PARQUET)\n",
      "            MATCH_BY_COLUMN_NAME = 'CASE_INSENSITIVE'\n",
      "        \n",
      "Successfully loaded data into production_countries\n",
      "Table MOVIES.MOVIE_BASE.spoken_languages created sucessfully\n",
      "Executing truncate query: TRUNCATE TABLE MOVIES.MOVIE_BASE.spoken_languages\n",
      "Executing copy query: \n",
      "            COPY INTO MOVIES.MOVIE_BASE.spoken_languages\n",
      "            FROM @S3_STAGE/etl/spoken_languages.parquet\n",
      "            FILE_FORMAT = (TYPE = PARQUET)\n",
      "            MATCH_BY_COLUMN_NAME = 'CASE_INSENSITIVE'\n",
      "        \n",
      "Successfully loaded data into spoken_languages\n",
      "Table MOVIES.MOVIE_BASE.ratings created sucessfully\n",
      "Executing truncate query: TRUNCATE TABLE MOVIES.MOVIE_BASE.ratings\n",
      "Executing copy query: \n",
      "            COPY INTO MOVIES.MOVIE_BASE.ratings\n",
      "            FROM @S3_STAGE/etl/ratings.parquet\n",
      "            FILE_FORMAT = (TYPE = PARQUET)\n",
      "            MATCH_BY_COLUMN_NAME = 'CASE_INSENSITIVE'\n",
      "        \n",
      "Successfully loaded data into ratings\n",
      "All of the data loaded successfully\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_movie.load(result, \"@S3_STAGE/etl/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datamart Transform Sucessfully\n"
     ]
    }
   ],
   "source": [
    "my_movie.transform_to_mart()\n",
    "my_movie.snow_handler.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
